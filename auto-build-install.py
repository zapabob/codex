#!/usr/bin/env python3
"""
Codex Automatic Build & Install (Enhanced)
ã‚¯ãƒªãƒ¼ãƒ³ãƒ“ãƒ«ãƒ‰â†’ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«â†’Git Push
é›»æºæ–­å¯¾ç­–ï¼šãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãƒ»è‡ªå‹•å†é–‹
"""

import subprocess
import shutil
import os
import sys
import json
import signal
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import threading

try:
    from tqdm import tqdm
except ImportError:
    print("tqdm not found, installing...")
    subprocess.run(["py", "-3", "-m", "pip", "install", "tqdm"], check=True, encoding='utf-8', errors='replace')
    from tqdm import tqdm

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
SESSION_ID = datetime.now().strftime('%Y%m%d_%H%M%S')
CHECKPOINT_FILE = Path(f"_docs/.build_checkpoint_{SESSION_ID}.json")
BACKUP_DIR = Path("_docs/build_backups")
BACKUP_DIR.mkdir(parents=True, exist_ok=True)

# ãƒ­ã‚°è¨­å®š
log_file = f"_docs/build-log-{SESSION_ID}.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
class BuildState:
    def __init__(self):
        self.completed_steps = []
        self.current_step = None
        self.build_times = {}
        self.errors = []
        self.start_time = datetime.now()
        
    def save_checkpoint(self):
        """ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜"""
        checkpoint_data = {
            "session_id": SESSION_ID,
            "completed_steps": self.completed_steps,
            "current_step": self.current_step,
            "build_times": self.build_times,
            "errors": self.errors,
            "timestamp": datetime.now().isoformat()
        }
        with open(CHECKPOINT_FILE, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
        logging.debug(f"Checkpoint saved: {self.current_step}")
    
    @staticmethod
    def load_checkpoint() -> Optional['BuildState']:
        """æœ€æ–°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­ã¿è¾¼ã¿"""
        checkpoints = list(Path("_docs").glob(".build_checkpoint_*.json"))
        if not checkpoints:
            return None
        
        latest = max(checkpoints, key=lambda p: p.stat().st_mtime)
        try:
            with open(latest, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            state = BuildState()
            state.completed_steps = data.get("completed_steps", [])
            state.current_step = data.get("current_step")
            state.build_times = data.get("build_times", {})
            state.errors = data.get("errors", [])
            logging.info(f"ğŸ“¦ Checkpoint loaded: {len(state.completed_steps)} steps completed")
            return state
        except Exception as e:
            logging.warning(f"Failed to load checkpoint: {e}")
            return None

build_state = BuildState()

# ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆCtrl+C / ç•°å¸¸çµ‚äº†æ™‚ï¼‰
def signal_handler(signum, frame):
    """ç·Šæ€¥ä¿å­˜"""
    logging.warning("âš ï¸  Interrupted! Saving checkpoint...")
    build_state.save_checkpoint()
    logging.info(f"Checkpoint saved to: {CHECKPOINT_FILE}")
    sys.exit(1)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)
if os.name == 'nt':  # Windows
    signal.signal(signal.SIGBREAK, signal_handler)

def run_command(cmd, cwd=None, timeout=300, use_cache=False, show_realtime=False):
    """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆãƒšãƒ¼ã‚¸ãƒ£ãƒ¼å›é¿ï¼‹ä¸¦åˆ—ãƒ“ãƒ«ãƒ‰æœ€é©åŒ–ï¼‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ï¼‰"""
    env = os.environ.copy()
    env['PAGER'] = ''
    env['GIT_PAGER'] = 'cat'
    
    # ä¸¦åˆ—ãƒ“ãƒ«ãƒ‰ã‚¸ãƒ§ãƒ–æ•°æœ€é©åŒ–ï¼ˆRTX3080ç’°å¢ƒ: 12ã‚³ã‚¢æƒ³å®šï¼‰
    env['CARGO_BUILD_JOBS'] = '12'
    env['RUSTFLAGS'] = '-C target-cpu=native'
    
    # sccacheæœ‰åŠ¹åŒ–ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
    if use_cache and check_sccache():
        env['RUSTC_WRAPPER'] = 'sccache'
    
    try:
        if show_realtime:
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰
            process = subprocess.Popen(
                cmd,
                cwd=cwd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                encoding='utf-8',
                errors='replace',
                env=env,
                shell=True,
                bufsize=1
            )
            
            output_lines = []
            for line in process.stdout:
                output_lines.append(line)
                # é‡è¦ãªè¡Œã ã‘è¡¨ç¤º
                if any(keyword in line for keyword in ["Compiling", "Finished", "error:", "warning:"]):
                    print(f"  {line.rstrip()}")
            
            process.wait(timeout=timeout)
            full_output = ''.join(output_lines)
            return process.returncode, full_output, ""
        else:
            result = subprocess.run(
                cmd,
                cwd=cwd,
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace',
                timeout=timeout,
                env=env,
                shell=True
            )
            return result.returncode, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        return -1, "", f"Command timed out after {timeout}s"
    except Exception as e:
        return -1, "", str(e)

def run_with_retry(cmd, cwd=None, max_retries=3, **kwargs):
    """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ"""
    for attempt in range(max_retries):
        code, out, err = run_command(cmd, cwd=cwd, **kwargs)
        if code == 0:
            return code, out, err
        
        if attempt < max_retries - 1:
            logging.warning(f"  Retry {attempt + 1}/{max_retries - 1}...")
            build_state.save_checkpoint()  # ãƒªãƒˆãƒ©ã‚¤å‰ã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
        else:
            logging.error(f"  Failed after {max_retries} attempts")
            build_state.errors.append({
                "cmd": cmd,
                "error": err[:500],
                "timestamp": datetime.now().isoformat()
            })
    
    return code, out, err

def check_sccache():
    """sccacheã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª"""
    try:
        result = subprocess.run(["sccache", "--version"], capture_output=True, encoding='utf-8', errors='replace')
        return result.returncode == 0
    except FileNotFoundError:
        return False

def get_sccache_stats():
    """sccacheçµ±è¨ˆå–å¾—"""
    try:
        result = subprocess.run(["sccache", "--show-stats"], capture_output=True, text=True, encoding='utf-8', errors='replace')
        if result.returncode == 0:
            return result.stdout
        return None
    except:
        return None

def check_disk_space(required_gb=10):
    """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯"""
    try:
        if os.name == 'nt':
            import ctypes
            free_bytes = ctypes.c_ulonglong(0)
            ctypes.windll.kernel32.GetDiskFreeSpaceExW(
                ctypes.c_wchar_p(str(Path.cwd())),
                None, None, ctypes.pointer(free_bytes)
            )
            free_gb = free_bytes.value / (1024**3)
        else:
            stat = os.statvfs(Path.cwd())
            free_gb = (stat.f_bavail * stat.f_frsize) / (1024**3)
        
        if free_gb < required_gb:
            logging.warning(f"âš ï¸  Low disk space: {free_gb:.1f} GB (recommended: {required_gb} GB)")
            return False
        else:
            logging.info(f"âœ“ Disk space: {free_gb:.1f} GB available")
            return True
    except:
        return True  # ãƒã‚§ãƒƒã‚¯å¤±æ•—æ™‚ã¯ç¶šè¡Œ

def check_rust_version():
    """Rustãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª"""
    try:
        result = subprocess.run(["cargo", "--version"], capture_output=True, text=True, encoding='utf-8', errors='replace')
        if result.returncode == 0:
            version = result.stdout.strip()
            logging.info(f"ğŸ¦€ Rust: {version}")
            return True
        return False
    except:
        logging.error("âŒ Rust not found! Install from https://rustup.rs/")
        return False

def main():
    global build_state
    
    logging.info("=" * 70)
    logging.info("  ğŸš€ Codex Automatic Build & Install (Enhanced)")
    logging.info("  GPU-Optimized | Checkpoint System | Auto-Recovery")
    logging.info("=" * 70)
    print()
    
    # å‰å›ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¢ºèª
    if "--resume" in sys.argv:
        loaded_state = BuildState.load_checkpoint()
        if loaded_state:
            build_state = loaded_state
            logging.info(f"ğŸ”„ Resuming from checkpoint: {len(build_state.completed_steps)} steps done")
        else:
            logging.info("No checkpoint found, starting fresh")
    
    # äº‹å‰ãƒã‚§ãƒƒã‚¯
    logging.info("ğŸ“‹ Pre-build Checks:")
    if not check_rust_version():
        sys.exit(1)
    check_disk_space(required_gb=10)
    
    # sccacheãƒã‚§ãƒƒã‚¯
    use_sccache = check_sccache()
    if use_sccache:
        logging.info("  âœ“ sccache available (compile cache enabled)")
        # åˆæœŸçµ±è¨ˆ
        stats = get_sccache_stats()
        if stats:
            logging.debug(f"sccache initial stats:\n{stats}")
    else:
        logging.info("  â„¹ sccache not found (building without cache)")
    
    root_dir = Path.cwd()
    codex_rs_dir = root_dir / "codex-rs"
    
    # ãƒ“ãƒ«ãƒ‰è¨­å®šè¡¨ç¤º
    print()
    logging.info("âš™ï¸  Build Configuration:")
    logging.info(f"  - Session ID: {SESSION_ID}")
    logging.info("  - Parallel jobs: 12 (RTX3080 CPU cores)")
    logging.info("  - Target CPU: native")
    logging.info(f"  - Cache: {'sccache' if use_sccache else 'disabled'}")
    logging.info(f"  - Log file: {log_file}")
    print()
    
    # Progress bar for overall progress
    total_steps = 6
    with tqdm(total=total_steps, desc="Overall Progress", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:
        
        # Step 1: Clean (ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½)
        step_name = "clean"
        if step_name not in build_state.completed_steps:
            build_state.current_step = step_name
            pbar.set_description("[1/6] ğŸ§¹ Cleaning")
            logging.info("[1/6] Cleaning build artifacts...")
            
            if "--skip-clean" not in sys.argv:
                code, out, err = run_command("cargo clean", cwd=codex_rs_dir)
                if code == 0:
                    logging.info("  âœ“ Clean complete")
                else:
                    logging.warning("  âš  Clean had issues (continuing)")
            else:
                logging.info("  â­ Skipped (--skip-clean flag)")
            
            build_state.completed_steps.append(step_name)
            build_state.save_checkpoint()
        else:
            logging.info("[1/6] ğŸ§¹ Cleaning (already completed)")
        pbar.update(1)
    
        # Step 2: Build Deep Research
        step_name = "deep-research"
        if step_name not in build_state.completed_steps:
            build_state.current_step = step_name
            pbar.set_description("[2/6] ğŸ”¬ Building Deep Research")
            logging.info("[2/6] Building Deep Research module (parallel: 12 jobs)...")
            
            start_time = datetime.now()
            code, out, err = run_with_retry(
                "cargo build --release -p codex-deep-research",
                cwd=codex_rs_dir,
                timeout=600,
                use_cache=use_sccache,
                show_realtime=True,
                max_retries=2
            )
            elapsed = (datetime.now() - start_time).total_seconds()
            build_state.build_times[step_name] = elapsed
            
            if code == 0 or "Finished" in out or "Finished" in err:
                logging.info(f"  âœ“ Deep Research compiled in {elapsed:.1f}s")
                build_state.completed_steps.append(step_name)
            else:
                logging.error(f"  âŒ Build failed: {err[:300]}")
                build_state.save_checkpoint()
                sys.exit(1)
            
            build_state.save_checkpoint()
        else:
            logging.info("[2/6] ğŸ”¬ Deep Research (already completed)")
        pbar.update(1)
    
        # Step 3: Build Key Binaries
        step_name = "core-binaries"
        if step_name not in build_state.completed_steps:
            build_state.current_step = step_name
            pbar.set_description("[3/6] ğŸ”§ Building Core Binaries")
            logging.info("[3/6] Building Core Binaries...")
            binaries = ["codex-tui", "codex-mcp-server"]
            
            for binary in tqdm(binaries, desc="Building binaries", leave=False):
                binary_step = f"{step_name}:{binary}"
                if binary_step not in build_state.completed_steps:
                    logging.info(f"  Building {binary} (parallel: 12 jobs)...")
                    
                    start_time = datetime.now()
                    code, out, err = run_with_retry(
                        f"cargo build --release -p {binary}",
                        cwd=codex_rs_dir,
                        timeout=600,
                        use_cache=use_sccache,
                        show_realtime=True,
                        max_retries=2
                    )
                    elapsed = (datetime.now() - start_time).total_seconds()
                    build_state.build_times[binary] = elapsed
                    
                    if code == 0 or "Finished" in out or "Finished" in err:
                        logging.info(f"  âœ“ {binary} compiled in {elapsed:.1f}s")
                        build_state.completed_steps.append(binary_step)
                    else:
                        logging.error(f"  âŒ {binary} build failed")
                        build_state.save_checkpoint()
                        sys.exit(1)
                    
                    build_state.save_checkpoint()
                else:
                    logging.info(f"  â­ {binary} (already completed)")
            
            build_state.completed_steps.append(step_name)
            build_state.save_checkpoint()
        else:
            logging.info("[3/6] ğŸ”§ Core Binaries (already completed)")
        pbar.update(1)
    
        # Step 4: Verify Binaries
        pbar.set_description("[4/6] Verifying Binaries")
        logging.info("[4/6] Verifying Binaries...")
        release_dir = codex_rs_dir / "target" / "release"
        exe_files = list(release_dir.glob("codex-*.exe"))
        logging.info(f"  [OK] Found {len(exe_files)} binaries:")
        for exe in exe_files[:5]:
            size_mb = exe.stat().st_size / (1024 * 1024)
            logging.info(f"    - {exe.name} ({size_mb:.1f} MB)")
        pbar.update(1)
    
        # Step 5: Global Installation
        pbar.set_description("[5/6] Installing Globally")
        logging.info("[5/6] Installing Globally...")
        install_dir = Path.home() / ".codex" / "bin"
        install_dir.mkdir(parents=True, exist_ok=True)
        
        installed = 0
        # Copy binaries
        install_items = ["codex-tui.exe", "codex-mcp-server.exe", "codex-mcp-client.exe"]
        for exe in tqdm(install_items, desc="Installing binaries", leave=False):
            src = release_dir / exe
            if src.exists():
                shutil.copy2(src, install_dir / exe)
                logging.info(f"  [OK] Installed: {exe}")
                installed += 1
        
        # Copy MCP scripts
        mcp_scripts = [
            ("codex-rs/mcp-server/dist/index.js", "index.js"),
            ("codex-rs/deep-research/mcp-server/web-search.js", "web-search.js")
        ]
        for src_rel, dest_name in tqdm(mcp_scripts, desc="Installing MCP scripts", leave=False):
            src = root_dir / src_rel
            if src.exists():
                shutil.copy2(src, install_dir / dest_name)
                logging.info(f"  [OK] Installed: {dest_name}")
                installed += 1
        
        # Copy agents
        agents_src = root_dir / ".codex" / "agents"
        agents_dest = Path.home() / ".codex" / "agents"
        agent_count = 0
        if agents_src.exists():
            agents_dest.mkdir(parents=True, exist_ok=True)
            yaml_files = list(agents_src.glob("*.yaml"))
            for yaml_file in tqdm(yaml_files, desc="Installing agents", leave=False):
                shutil.copy2(yaml_file, agents_dest / yaml_file.name)
            agent_count = len(list(agents_dest.glob("*.yaml")))
            logging.info(f"  [OK] Installed {agent_count} agents")
        
        logging.info(f"  Installation: {install_dir}")
        logging.info(f"  Total files: {installed}")
        pbar.update(1)
    
        # Step 6: Git Commit & Push
        pbar.set_description("[6/6] Git Operations")
        logging.info("[6/6] Git Commit & Push...")
        
        # Add all
        run_command("git add -A")
        
        # Check status
        code, out, err = run_command("git status --porcelain")
        if out.strip():
            # Commit
            commit_msg = f"""feat: ã‚¯ãƒªãƒ¼ãƒ³ãƒ“ãƒ«ãƒ‰ï¼‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†

- cargo cleanå®Ÿè¡Œ
- Deep Researchæœ¬ç•ªãƒ“ãƒ«ãƒ‰
- Core binaries: codex-tui, codex-mcp-server
- Global install: ~/.codex/bin
- {installed} files installed
- {agent_count} agents configured
- å®ŸWebæ¤œç´¢APIçµ±åˆ

Status: Production Ready"""
            
            run_command(f'git commit -m "{commit_msg}"')
            logging.info("  [OK] Committed")
            
            # Push
            code, out, err = run_command("git push origin main")
            if code == 0:
                logging.info("  [OK] Pushed to GitHub")
            else:
                logging.warning(f"  [WARN] Push: {err[:100]}")
        else:
            logging.info("  [INFO] No changes to commit")
        pbar.update(1)
    
    # Summary
    total_time = (datetime.now() - build_state.start_time).total_seconds()
    print()
    logging.info("=" * 70)
    logging.info("  âœ… Installation Complete!")
    logging.info("=" * 70)
    print()
    
    logging.info("ğŸ“¦ Installation Summary:")
    logging.info(f"  - Installed to: {install_dir}")
    logging.info(f"  - Files: {installed} binaries + {agent_count} agents")
    logging.info(f"  - Total time: {total_time/60:.1f} minutes ({total_time:.0f}s)")
    
    if build_state.build_times:
        logging.info("\nâ±ï¸  Build Times:")
        for name, time in build_state.build_times.items():
            logging.info(f"  - {name}: {time:.1f}s")
    
    # sccacheçµ±è¨ˆï¼ˆæœ€çµ‚ï¼‰
    if use_sccache:
        stats = get_sccache_stats()
        if stats:
            logging.info("\nğŸ“Š sccache Stats:")
            for line in stats.split('\n')[:10]:  # æœ€åˆã®10è¡Œã ã‘
                if line.strip():
                    logging.info(f"  {line}")
    
    if build_state.errors:
        logging.warning(f"\nâš ï¸  Errors: {len(build_state.errors)}")
        for i, err in enumerate(build_state.errors[:3], 1):
            logging.warning(f"  {i}. {err['cmd']}: {err['error'][:100]}")
    
    logging.info(f"\nğŸ“ Log saved: {log_file}")
    logging.info(f"ğŸ’¾ Checkpoint: {CHECKPOINT_FILE}")
    
    print()
    logging.info("ğŸ§ª Quick Test:")
    logging.info(f'  cd "{install_dir}"')
    logging.info("  .\\codex-tui.exe --version")
    
    print()
    logging.info("ğŸ‰ Status: Production Ready âœ…")
    print()
    logging.info("Usage:")
    logging.info("  py -3 auto-build-install.py            # Full build")
    logging.info("  py -3 auto-build-install.py --skip-clean   # Skip clean step")
    logging.info("  py -3 auto-build-install.py --resume       # Resume from checkpoint")
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    try:
        CHECKPOINT_FILE.unlink()
        logging.debug(f"Checkpoint cleaned: {CHECKPOINT_FILE}")
    except:
        pass

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logging.warning("\nâš ï¸  Build interrupted by user")
        build_state.save_checkpoint()
        logging.info(f"Checkpoint saved. Resume with: py -3 auto-build-install.py --resume")
        sys.exit(1)
    except Exception as e:
        logging.error(f"\nâŒ Fatal error: {e}")
        build_state.save_checkpoint()
        logging.info(f"Checkpoint saved to: {CHECKPOINT_FILE}")
        raise

